#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¾®åšçˆ¬è™«ç³»ç»Ÿæµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯å„æ¨¡å—åŠŸèƒ½å’Œé…ç½®æ˜¯å¦æ­£å¸¸
"""

import os
import sys
import time
import csv
import requests

# æ·»åŠ spiderç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'spider'))

try:
    from config import get_config_manager, HEADERS
except ImportError as e:
    print(f"é…ç½®æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def test_config():
    """æµ‹è¯•é…ç½®ç³»ç»Ÿ"""
    print("=== æµ‹è¯•é…ç½®ç³»ç»Ÿ ===")
    config = get_config_manager()
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = config.get_config_stats()
    print(f"User-Agentæ•°é‡: {stats['user_agents_count']}")
    print(f"å¯ç”¨ä»£ç†æ•°é‡: {stats['working_proxies_count']}")
    print(f"ä»£ç†çŠ¶æ€: {'å¯ç”¨' if stats['proxy_enabled'] else 'ç¦ç”¨'}")
    print(f"é»˜è®¤è¶…æ—¶: {stats['default_timeout']}ç§’")
    print(f"å»¶è¿ŸèŒƒå›´: {stats['delay_range']}ç§’")
    
    # æµ‹è¯•éšæœºè¯·æ±‚å¤´
    headers = config.get_random_headers()
    print(f"éšæœºUser-Agent: {headers['User-Agent'][:50]}...")
    
    print("âœ… é…ç½®ç³»ç»Ÿæµ‹è¯•é€šè¿‡\n")

def test_network_connection():
    """æµ‹è¯•ç½‘ç»œè¿æ¥"""
    print("=== æµ‹è¯•ç½‘ç»œè¿æ¥ ===")
    config = get_config_manager()
    
    # æµ‹è¯•åŸºç¡€è¿æ¥
    test_urls = [
        'http://httpbin.org/ip',
        'https://www.baidu.com',
        'https://weibo.com'
    ]
    
    for url in test_urls:
        try:
            headers = config.get_random_headers()
            response = requests.get(url, headers=headers, timeout=10)
            print(f"âœ… {url} - çŠ¶æ€ç : {response.status_code}")
        except Exception as e:
            print(f"âŒ {url} - é”™è¯¯: {e}")
    
    print("ç½‘ç»œè¿æ¥æµ‹è¯•å®Œæˆ\n")

def test_weibo_api():
    """æµ‹è¯•å¾®åšAPIå¯ç”¨æ€§"""
    print("=== æµ‹è¯•å¾®åšAPIå¯ç”¨æ€§ ===")
    config = get_config_manager()
    
    # æµ‹è¯•å¾®åšçƒ­æœAPI
    api_url = 'https://weibo.com/ajax/feed/hottimeline'
    params = {
        'since_id': '0',
        'refresh': '0',
        'group_id': '102803',
        'containerid': '102803',
        'extparam': 'discover|new_feed',
        'max_id': '0',
        'count': '10'
    }
    
    try:
        headers = config.get_random_headers()
        response = requests.get(api_url, headers=headers, params=params, timeout=15)
        print(f"å¾®åšAPIçŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            if 'statuses' in data:
                print(f"âœ… è·å–åˆ° {len(data['statuses'])} æ¡çƒ­æœæ•°æ®")
                print("âœ… å¾®åšAPIå¯æ­£å¸¸è®¿é—®")
            else:
                print(f"âŒ APIå“åº”æ ¼å¼å¼‚å¸¸: {data}")
        elif response.status_code == 403:
            print("âŒ 403ç¦æ­¢è®¿é—® - éœ€è¦æ›´æ–°Cookieæˆ–æ·»åŠ ä»£ç†")
            print("ğŸ“‹ è¯·æ›´æ–°config.pyä¸­çš„Cookieé…ç½®")
        else:
            print(f"âŒ APIè®¿é—®å¤±è´¥: {response.status_code}")
            print(f"å“åº”å†…å®¹: {response.text[:200]}")
            
    except Exception as e:
        print(f"âŒ APIæµ‹è¯•å¼‚å¸¸: {e}")
    
    print()

def test_csv_files():
    """æµ‹è¯•CSVæ–‡ä»¶è¯»å†™"""
    print("=== æµ‹è¯•CSVæ–‡ä»¶åŠŸèƒ½ ===")
    
    # æ£€æŸ¥ç°æœ‰æ•°æ®æ–‡ä»¶
    data_files = [
        'articleData.csv',
        'commentsData.csv',
        'userInfo.csv',
        'navData.csv'
    ]
    
    base_dir = os.path.dirname(os.path.dirname(__file__))
    
    for file_name in data_files:
        # é¦–å…ˆæ£€æŸ¥dataæ–‡ä»¶å¤¹
        data_file_path = os.path.join(base_dir, 'data', file_name)
        # ç„¶åæ£€æŸ¥spideræ–‡ä»¶å¤¹
        spider_file_path = os.path.join(base_dir, 'spider', file_name)
        
        file_path = None
        if os.path.exists(data_file_path):
            file_path = data_file_path
        elif os.path.exists(spider_file_path):
            file_path = spider_file_path
        
        if file_path:
            try:
                with open(file_path, 'r', encoding='utf8') as f:
                    reader = csv.reader(f)
                    rows = list(reader)
                    print(f"âœ… {file_name} - {len(rows)-1} æ¡æ•°æ®è®°å½• (ä½ç½®: {os.path.relpath(file_path, base_dir)})")
            except Exception as e:
                print(f"âŒ {file_name} - è¯»å–é”™è¯¯: {e}")
        else:
            print(f"âš ï¸  {file_name} - æ–‡ä»¶ä¸å­˜åœ¨")
    
    print()

def test_spider_modules():
    """æµ‹è¯•çˆ¬è™«æ¨¡å—å¯¼å…¥"""
    print("=== æµ‹è¯•çˆ¬è™«æ¨¡å—å¯¼å…¥ ===")
    
    modules_to_test = [
        ('spiderContent', 'æ–‡ç« çˆ¬å–æ¨¡å—'),
        ('spiderComments', 'è¯„è®ºçˆ¬å–æ¨¡å—'), 
        ('spiderUserInfo', 'ç”¨æˆ·ä¿¡æ¯çˆ¬å–æ¨¡å—'),
        ('spiderMaster', 'ä¸»æ§åˆ¶æ¨¡å—')
    ]
    
    sys.path.append('spider')
    
    for module_name, description in modules_to_test:
        try:
            __import__(module_name)
            print(f"âœ… {description} ({module_name}) - å¯¼å…¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ {description} ({module_name}) - å¯¼å…¥å¤±è´¥: {e}")
    
    print()

def generate_test_report():
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("=== ç³»ç»ŸçŠ¶æ€æŠ¥å‘Š ===")
    config = get_config_manager()
    stats = config.get_config_stats()
    
    print(f"Pythonç‰ˆæœ¬: {sys.version.split()[0]}")
    print(f"å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"é…ç½®çŠ¶æ€: æ­£å¸¸")
    print(f"ä»£ç†çŠ¶æ€: {'å¯ç”¨' if stats['proxy_enabled'] else 'ç¦ç”¨'}")
    print(f"å¯ç”¨ä»£ç†: {stats['working_proxies_count']} ä¸ª")
    print(f"User-Agentæ± : {stats['user_agents_count']} ä¸ª")
    print()
    
    # æ£€æŸ¥å…³é”®æ–‡ä»¶
    critical_files = [
        'spider/config.py',
        'spider/spiderContent.py', 
        'spider/spiderComments.py',
        'spider/spiderUserInfo.py',
        'spider/spiderMaster.py'
    ]
    
    print("å…³é”®æ–‡ä»¶æ£€æŸ¥:")
    for file_path in critical_files:
        if os.path.exists(file_path):
            size = os.path.getsize(file_path)
            print(f"âœ… {file_path} ({size} bytes)")
        else:
            print(f"âŒ {file_path} - ç¼ºå¤±")
    
    print("\nğŸ“‹ ä½¿ç”¨å»ºè®®:")
    if stats['working_proxies_count'] == 0:
        print("- å»ºè®®è¿è¡Œ spider/proxy_fetcher.py è·å–ä»£ç†IP")
    
    print("- å¦‚é‡403é”™è¯¯ï¼Œè¯·æ›´æ–°config.pyä¸­çš„Cookie")
    print("- å»ºè®®å…ˆè¿è¡Œå°è§„æ¨¡æµ‹è¯•éªŒè¯åŠŸèƒ½")
    print("- ä½¿ç”¨ python spider/spiderMaster.py å¯åŠ¨å®Œæ•´çˆ¬è™«")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¾®åšèˆ†æƒ…åˆ†æçˆ¬è™«ç³»ç»Ÿ - åŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    # ä¾æ¬¡æ‰§è¡Œå„é¡¹æµ‹è¯•
    test_config()
    test_network_connection() 
    test_weibo_api()
    test_csv_files()
    test_spider_modules()
    generate_test_report()
    
    print("ğŸ æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ å¦‚æœæ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œæ‚¨å¯ä»¥:")
    print("1. ä½¿ç”¨ python spider/spiderMaster.py å¯åŠ¨å®Œæ•´çˆ¬è™«")
    print("2. æ ¹æ®éœ€è¦é€‰æ‹©ä¸åŒçš„çˆ¬å–æ¨¡å¼")
    print("3. æŸ¥çœ‹ç”Ÿæˆçš„CSVæ–‡ä»¶è·å–çˆ¬å–ç»“æœ")

if __name__ == '__main__':
    main()