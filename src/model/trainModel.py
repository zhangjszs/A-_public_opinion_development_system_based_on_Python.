"""
sentiment_model.py  â€”â€” 2025â€‘05â€‘04 å®Œæ•´ä¿®æ­£ç‰ˆ
ä¾èµ–: pandas numpy scikit-learn matplotlib seaborn joblib
å¯é€‰: imbalancedâ€‘learn (è‹¥éœ€ SMOTE ç­‰è¿‡é‡‡æ ·)
"""

from __future__ import annotations

import warnings
from collections import Counter
from pathlib import Path

import joblib

# -------------------------------------------------------------------
# Matplotlib ä¸­æ–‡æ”¯æŒ
# -------------------------------------------------------------------
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    ConfusionMatrixDisplay,
    RocCurveDisplay,
    classification_report,
    confusion_matrix,
)
from sklearn.model_selection import (
    StratifiedKFold,
    cross_validate,
    train_test_split,
)
from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC

matplotlib.rcParams["font.family"] = ["SimHei", "Microsoft YaHei", "SimSun"]
matplotlib.rcParams["axes.unicode_minus"] = False


# -------------------------------------------------------------------
# æ•°æ®åŠ è½½
# -------------------------------------------------------------------
def load_data(csv_path: str | Path) -> pd.DataFrame:
    """è¯»å– csv ä¸º DataFrameï¼Œå¹¶åšåŸºæœ¬æ¸…æ´—"""
    return (
        pd.read_csv(csv_path, header=None, names=["text", "label"])
        .dropna(subset=["text", "label"])
        .drop_duplicates()
        .reset_index(drop=True)
    )


try:
    from model_utils import WeightedMultinomialNB
except ImportError:
    # Try relative import if running as module
    from .model_utils import WeightedMultinomialNB

# -------------------------------------------------------------------
# æ¨¡å‹åˆ—è¡¨
# -------------------------------------------------------------------
MODELS = {
    "NaiveBayes": WeightedMultinomialNB(),
    "LogReg": LogisticRegression(max_iter=1000, class_weight="balanced"),
    "LinearSVM": LinearSVC(class_weight="balanced"),
    "RandomForest": RandomForestClassifier(
        n_estimators=300, n_jobs=-1, random_state=42, class_weight="balanced"
    ),
}


def build_pipeline(estimator):
    """ç»Ÿä¸€çš„ TFâ€‘IDF + åˆ†ç±»å™¨æµæ°´çº¿"""
    return Pipeline(
        steps=[
            ("tfidf", TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),
            ("clf", estimator),
        ]
    )


# -------------------------------------------------------------------
# äº¤å‰éªŒè¯ + å¯è§†åŒ–
# -------------------------------------------------------------------
def evaluate_models(
    df: pd.DataFrame,
    k_folds: int | None = None,
    scoring: str = "macro_f1",
) -> dict[str, np.ndarray]:
    """
    äº¤å‰éªŒè¯æ¯”è¾ƒå„æ¨¡å‹ã€‚
    scoring å–å€¼ï¼š'macro_f1' | 'bal_acc' | 'accuracy'
    """
    X, y = df["text"], df["label"]

    # åŠ¨æ€å†³å®š n_splitsï¼Œé¿å…æœ€å°ç±»åˆ« < n_splits
    min_class = y.value_counts().min()
    n_splits = k_folds or max(2, min(5, min_class))
    if min_class < 10:
        warnings.warn(
            f"âš ï¸ æœ€å°ç±»åˆ«æ ·æœ¬æ•°åªæœ‰ {min_class}ï¼Œå·²è‡ªåŠ¨å°† n_splits è®¾ä¸º {n_splits}ã€‚",
            UserWarning,
            stacklevel=2,
        )

    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)

    # å¤šæŒ‡æ ‡
    cv_metrics = {
        "accuracy": "accuracy",
        "macro_f1": "f1_macro",
        "bal_acc": "balanced_accuracy",
    }

    results = {}

    for name, est in MODELS.items():
        pipe = build_pipeline(est)
        cv_res = cross_validate(
            pipe,
            X,
            y,
            cv=skf,
            scoring=cv_metrics,
            n_jobs=-1,
            return_train_score=False,
        )
        key = f"test_{scoring}"  # è‡ªåŠ¨åŠ å‰ç¼€
        results[name] = cv_res[key]
        print(
            f"{name:<12} | {scoring}={cv_res[key].mean():.4f}Â±{cv_res[key].std():.4f} "
            f"| acc={cv_res['test_accuracy'].mean():.4f}"
        )

    # ç®±çº¿å›¾
    plt.figure(figsize=(8, 5))
    sns.boxplot(data=pd.DataFrame(results))
    plt.title(f"{n_splits}-Fold {scoring} Comparison")
    plt.ylabel(scoring)
    plt.tight_layout()
    # plt.show()

    return results


# -------------------------------------------------------------------
# è®­ç»ƒæœ€ç»ˆæ¨¡å‹ + æ··æ·†çŸ©é˜µ / ROC
# -------------------------------------------------------------------
def train_best_model(df: pd.DataFrame, model_name: str = "NaiveBayes"):
    X_train, X_test, y_train, y_test = train_test_split(
        df["text"],
        df["label"],
        test_size=0.2,
        stratify=df["label"],
        random_state=42,
    )
    pipe = build_pipeline(MODELS[model_name])
    pipe.fit(X_train, y_train)
    y_pred = pipe.predict(X_test)

    print("\nğŸ¯ Classification Report")
    print(classification_report(y_test, y_pred, digits=4))

    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_test, y_pred, labels=np.unique(y_test))
    ConfusionMatrixDisplay(cm, display_labels=np.unique(y_test)).plot(
        cmap="Blues", xticks_rotation=45
    )
    plt.title(f"{model_name} Confusion Matrix")
    plt.tight_layout()
    # plt.show()

    # ROCï¼ˆä»…äºŒåˆ†ç±»ä¸”æ”¯æŒ decision_functionï¼‰
    if len(np.unique(y_test)) == 2 and hasattr(pipe, "decision_function"):
        RocCurveDisplay.from_predictions(y_test, pipe.decision_function(X_test))
        plt.title(f"{model_name} ROC Curve")
        plt.tight_layout()
        # plt.show()

    # ä¿å­˜æ¨¡å‹
    output_path = Path(__file__).parent / "best_sentiment_model.pkl"
    joblib.dump(pipe, output_path)
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜ä¸º {output_path}")
    return pipe


# -------------------------------------------------------------------
# æ¨ç†æ¥å£ï¼ˆå•ä¾‹ï¼‰
# -------------------------------------------------------------------
class SentimentPredictor:
    _model = None

    @classmethod
    def load(cls, path: str = "best_sentiment_model.pkl"):
        if cls._model is None:
            cls._model = joblib.load(path)
        return cls._model

    @classmethod
    def predict(cls, text: str):
        return cls.load().predict([text])[0]


# -------------------------------------------------------------------
# ä¸»æµç¨‹
# -------------------------------------------------------------------
if __name__ == "__main__":
    base_dir = Path(__file__).parent
    df = load_data(base_dir / "target.csv")
    print("ğŸ“Š æ ‡ç­¾åˆ†å¸ƒ:", Counter(df["label"]))

    # â‘  äº¤å‰éªŒè¯æ¯”è¾ƒ
    results = evaluate_models(df, scoring="macro_f1")

    # â‘¡ è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å‹
    # è®¡ç®—æ¯ä¸ªæ¨¡å‹çš„å¹³å‡å¾—åˆ†
    mean_scores = {name: scores.mean() for name, scores in results.items()}
    best_model_name = max(mean_scores, key=mean_scores.get)
    print(
        f"\nğŸ† æœ€ä½³æ¨¡å‹æ˜¯: {best_model_name} (å¾—åˆ†: {mean_scores[best_model_name]:.4f})"
    )

    # â‘¢ è®­ç»ƒä¿å­˜æœ€ä¼˜æ¨¡å‹
    trained_pipe = train_best_model(df, model_name=best_model_name)

    # â‘£ æ¨ç†ç¤ºä¾‹
    demo = "ç³Ÿç³•é€äº†"
    prediction = SentimentPredictor.predict(demo)
    print(f"â›… é¢„æµ‹ç»“æœ: {demo} => {prediction}")
